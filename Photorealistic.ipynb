{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u4dzcbGcTxq8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import vgg19 \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXIKboigT1dp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "from tqdm import tqdm \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Bnj9YemT-xo"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP9pFUiCUDVm"
   },
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        num_pad = int(np.floor(kernel_size / 2))\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=num_pad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVCn6ysKULjS"
   },
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super().__init__()\n",
    "        self.in_c = in_channels\n",
    "        self.out_c = out_channels\n",
    "        \n",
    "        self.identity_block = nn.Sequential(\n",
    "            ConvLayer(in_channels, out_channels//4, kernel_size=1, stride=1),\n",
    "            nn.InstanceNorm2d(out_channels//4),\n",
    "            nn.ReLU(),\n",
    "            ConvLayer(out_channels//4, out_channels//4, kernel_size=kernel_size, stride=stride),\n",
    "            nn.InstanceNorm2d(out_channels//4),\n",
    "            nn.ReLU(),\n",
    "            ConvLayer(out_channels//4, out_channels, kernel_size=1, stride=1),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            ConvLayer(in_channels, out_channels, 1, stride),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.identity_block(x)\n",
    "        if self.in_c == self.out_c:\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = self.shortcut(x)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwVwOgfGUP3t"
   },
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scale_factor, mode='bilinear'):\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.norm = nn.InstanceNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = F.interpolate(out, scale_factor=self.scale_factor, mode=self.mode, align_corners=False)\n",
    "        out = self.norm(out)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdCgzj5LUTR3"
   },
   "outputs": [],
   "source": [
    "def conv_down(in_c, out_c, stride=2):\n",
    "    return nn.Conv2d(in_c, out_c, kernel_size=3, stride=stride, padding=1)\n",
    "\n",
    "def upsample(input, scale_factor):\n",
    "    return F.interpolate(input=input, scale_factor=scale_factor, mode='bilinear', align_corners=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1MTd-oHUWeN"
   },
   "outputs": [],
   "source": [
    "class HRNet(nn.Module):\n",
    "  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1_1 = BottleneckBlock(3, 16)\n",
    "        \n",
    "        self.layer2_1 = BottleneckBlock(16, 32)\n",
    "        self.downsample2_1 = conv_down(16, 32)\n",
    "        \n",
    "        self.layer3_1 = BottleneckBlock(32, 32)\n",
    "        self.layer3_2 = BottleneckBlock(32, 32)\n",
    "        self.downsample3_1 = conv_down(32, 32)\n",
    "        self.downsample3_2 = conv_down(32, 32, stride=4)\n",
    "        self.downsample3_3 = conv_down(32, 32)\n",
    "        \n",
    "        self.layer4_1 = BottleneckBlock(64, 64)\n",
    "        self.layer5_1 = BottleneckBlock(192, 64)\n",
    "        self.layer6_1 = BottleneckBlock(64, 32)\n",
    "        self.layer7_1 = BottleneckBlock(32, 16)\n",
    "        self.layer8_1 = conv_down(16, 3, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        map1_1 = self.layer1_1(x)\n",
    "        \n",
    "        map2_1 = self.layer2_1(map1_1)\n",
    "        map2_2 = self.downsample2_1(map1_1)\n",
    "        \n",
    "        map3_1 = torch.cat((self.layer3_1(map2_1), upsample(map2_2, 2)), 1)\n",
    "        map3_2 = torch.cat((self.downsample3_1(map2_1), self.layer3_2(map2_2)), 1)\n",
    "        map3_3 = torch.cat((self.downsample3_2(map2_1), self.downsample3_3(map2_2)), 1)\n",
    "        \n",
    "        map4_1 = torch.cat((self.layer4_1(map3_1), upsample(map3_2, 2), upsample(map3_3, 4)), 1)\n",
    "        \n",
    "        out = self.layer5_1(map4_1)\n",
    "        out = self.layer6_1(out)\n",
    "        out = self.layer7_1(out)\n",
    "        out = self.layer8_1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sds7eeM7UbWi"
   },
   "outputs": [],
   "source": [
    "def load_image(path, size=None):\n",
    "\n",
    "    img = Image.open(path)\n",
    "\n",
    "    if size is not None:\n",
    "        img = img.resize((size, size))\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "    \n",
    "    img = transform(img).unsqueeze(0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGZxe7J5UfyH"
   },
   "outputs": [],
   "source": [
    "def im_convert(img):\n",
    "\n",
    "    img = img.to('cpu').clone().detach()\n",
    "    img = img.numpy().squeeze(0)\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    img = img * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    img = img.clip(0, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZwoSsdRUj9r"
   },
   "outputs": [],
   "source": [
    "def get_features(img, model, layers=None):\n",
    "\n",
    "    if layers is None:\n",
    "        layers = {\n",
    "            '0': 'conv1_1',   \n",
    "            '5': 'conv2_1',   \n",
    "            '10': 'conv3_1',  \n",
    "            '19': 'conv4_1',  \n",
    "            '28': 'conv5_1',  \n",
    "            \n",
    "            '21': 'conv4_2' \n",
    "        }\n",
    "    \n",
    "    features = {}\n",
    "    x = img\n",
    "    for name, layer in model._modules.items():\n",
    "        x = layer(x)\n",
    "        if name in layers:\n",
    "            features[layers[name]] = x\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVKXGxW5Uqff"
   },
   "outputs": [],
   "source": [
    "def get_gram_matrix(img):\n",
    "   \n",
    "    b, c, h, w = img.size()\n",
    "    img = img.view(b*c, h*w)\n",
    "    gram = torch.mm(img, img.t())\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0P57DDSUuKR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Nh5I7Y4WXNTv",
    "outputId": "1ad702f4-6ef2-4c49-83cf-bd1b85e1ec0f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H0oxB1VjXyr6",
    "outputId": "0a6aacfe-0eb1-44ce-cd7e-6627ba393e68"
   },
   "outputs": [],
   "source": [
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_lgG3UcU1C5"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.content_img = 'Durbar_Square2C_Kathmandu.jpg'\n",
    "        self.style_img = '1394124_10200591310296501_283160770_n.jpg'\n",
    "        self.use_batch = False\n",
    "        self.bs = 16\n",
    "        self.use_gpu = False\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if args.use_gpu:\n",
    "#    if torch.cuda.is_available():\n",
    "#        device = torch.device('cuda')\n",
    "#    else:\n",
    "#       raise Exception('GPU is not available')\n",
    "#else:\n",
    "#    device = torch.device('cpu')\n",
    "# Load VGG19 features\n",
    "vgg = vgg19(pretrained=True).features\n",
    "vgg = vgg.to(device)\n",
    "# We don't want to train VGG\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad_(False)\n",
    "    \n",
    "# Load style net\n",
    "style_net = HRNet()\n",
    "style_net = style_net.to(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WMkdCbuVbHG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "content_img = load_image(os.path.join(args.content_img), size=500)\n",
    "content_img = content_img.to(device)\n",
    "\n",
    "style_img = load_image(os.path.join(args.style_img))\n",
    "style_img = style_img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mplmjniBV2Kn",
    "outputId": "676df5ef-f063-4455-d0e4-a4d08689e271"
   },
   "outputs": [],
   "source": [
    "content_img.size(), style_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "colab_type": "code",
    "id": "gysuvKOEcMmT",
    "outputId": "d02b4bc9-0b23-4c7e-c5af-85688ccb809e"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(im_convert(content_img))\n",
    "ax2.imshow(im_convert(style_img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0Y45sjpcQSn"
   },
   "outputs": [],
   "source": [
    "content_features = get_features(content_img, vgg)\n",
    "style_features = get_features(style_img, vgg)\n",
    "\n",
    "style_gram_matrixs = {layer: get_gram_matrix(style_features[layer]) for layer in style_features}\n",
    "\n",
    "target = content_img.clone().requires_grad_(True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lp-ljao3cXR-"
   },
   "outputs": [],
   "source": [
    "style_weights = {\n",
    "     'conv1_1': 0.1,\n",
    "     'conv2_1': 0.2,\n",
    "     'conv3_1': 0.4,\n",
    "     'conv4_1': 0.8,\n",
    "     'conv5_1': 1.6\n",
    "}\n",
    "\n",
    "content_weight = 150\n",
    "style_weight = 1\n",
    "\n",
    "show_every = 100\n",
    "optim = torch.optim.Adam(style_net.parameters(), lr=5e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=200, gamma=0.9)\n",
    "steps = 1000\n",
    "\n",
    "content_loss_epoch = []\n",
    "style_loss_epoch = []\n",
    "total_loss_epoch = []\n",
    "output_image = content_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zLgv9TGbcfYx",
    "outputId": "4c365474-2f37-4a8b-f532-9850fc6e1aa8"
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(0, steps+1)):\n",
    "    scheduler.step()\n",
    "    \n",
    "    target = style_net(content_img).to(device)\n",
    "    target.requires_grad_(True)\n",
    "    \n",
    "    target_features = get_features(target, vgg)\n",
    "    content_loss = torch.mean((target_features['conv4_2'] - content_features['conv4_2']) ** 2)\n",
    "    \n",
    "    style_loss = 0\n",
    "    \n",
    "    for layer in style_weights:\n",
    "        target_feature = target_features[layer]\n",
    "        target_gram_matrix = get_gram_matrix(target_feature)\n",
    "        style_gram_matrix = style_gram_matrixs[layer]\n",
    "        \n",
    "        layer_style_loss = style_weights[layer] * torch.mean((target_gram_matrix - style_gram_matrix) ** 2)\n",
    "        b, c, h, w = target_feature.shape\n",
    "        style_loss += layer_style_loss / (c*h*w)\n",
    "        \n",
    "    total_loss = content_weight * content_loss + style_weight * style_loss\n",
    "    total_loss_epoch.append(total_loss.item())\n",
    "    \n",
    "    style_loss_epoch.append(style_weight * style_loss)\n",
    "    content_loss_epoch.append(content_weight * content_loss.item())\n",
    "    \n",
    "    optim.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if epoch % show_every == 0:\n",
    "        print(\"After %d criterions:\" % epoch)\n",
    "        print('Total loss: ', total_loss.item())\n",
    "        print('Content loss: ', content_loss.item())\n",
    "        print('Style loss: ', style_loss.item())\n",
    "        plt.imshow(im_convert(target))\n",
    "        plt.show()\n",
    "\n",
    "    output_image = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFBqIhGAc66W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
